{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPat3BFLjT2rPNjVXbidfcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaizFP/Dicoding--Analystic-Sentiments/blob/main/Pelatihan_SentimenAnalys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uu4iILEZYOSd",
        "outputId": "6f97abf3-09d1-42bf-dc59-06abb363c809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "!pip install gensim\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nama_file = '/content/sample_data/dataset_final2.csv'\n",
        "df_bersih = pd.read_csv(nama_file)\n",
        "print(df_bersih.head())"
      ],
      "metadata": {
        "id": "fmVpvGU1Yn6S",
        "outputId": "ad22a1a9-e91c-4aa6-8c8c-5e79277e083d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       clean_content  score\n",
            "0  aplikasi bantu order gojek berangkat pulang kerja      5\n",
            "1  drivernya ambil pas hujan ga kaya grab yg maha...      5\n",
            "2                                  wow uda tahin aja      5\n",
            "3                                               good      5\n",
            "4  kecewa bgt ga segercep grab pake gojek kapok b...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definisikan fungsi untuk mengubah rating menjadi label sentimen\n",
        "def tentukan_sentimen(rating):\n",
        "    if rating <= 2:\n",
        "        return 'negatif'  # Rating 1 dan 2 dianggap negatif\n",
        "    elif rating == 3:\n",
        "        return 'netral'   # Rating 3 dianggap netral\n",
        "    else: # rating 4 atau 5\n",
        "        return 'positif'  # Rating 4 dan 5 dianggap positif"
      ],
      "metadata": {
        "id": "PUHTFmFDmNym"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Terapkan fungsi tersebut pada kolom 'score' untuk membuat kolom baru 'sentimen'\n",
        "df_bersih['sentimen'] = df_bersih['score'].apply(tentukan_sentimen)"
      ],
      "metadata": {
        "id": "249JzEiVmoIF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih.info()"
      ],
      "metadata": {
        "id": "PmO1gNAUYwqX",
        "outputId": "1a16d6fb-e804-4c28-c968-5810d79d6bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10692 entries, 0 to 10691\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   clean_content  10692 non-null  object\n",
            " 1   score          10692 non-null  int64 \n",
            " 2   sentimen       10692 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 250.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih.dropna(subset=['score'], inplace=True)"
      ],
      "metadata": {
        "id": "U70ldYremvrY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih.info()"
      ],
      "metadata": {
        "id": "2XJtjVhymy-b",
        "outputId": "742b7980-ab14-4a74-d7fd-0f6e0106d5a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10692 entries, 0 to 10691\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   clean_content  10692 non-null  object\n",
            " 1   score          10692 non-null  int64 \n",
            " 2   sentimen       10692 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 250.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih['clean_content'].isnull().sum()"
      ],
      "metadata": {
        "id": "KzFT8feTY1c2",
        "outputId": "b258d49a-3f94-4c50-b8c4-d4fa23b67f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih['sentimen'].value_counts()"
      ],
      "metadata": {
        "id": "0bE0f5tuDJwY",
        "outputId": "cb4f72ae-21e1-4421-af3a-79db12c0e194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentimen\n",
              "positif    7372\n",
              "negatif    2916\n",
              "netral      404\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentimen</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positif</th>\n",
              "      <td>7372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negatif</th>\n",
              "      <td>2916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>netral</th>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih.duplicated().sum()"
      ],
      "metadata": {
        "id": "C1bkDkKn-emo",
        "outputId": "bcf2a6a8-e77e-4cda-e03a-124e2c64ca63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3341"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bersih['sentimen'].value_counts()"
      ],
      "metadata": {
        "id": "BINBFMctDh9_",
        "outputId": "7e9d67d0-d7ac-4bbf-f0ae-f364014f0a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentimen\n",
              "positif    7372\n",
              "negatif    2916\n",
              "netral      404\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentimen</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positif</th>\n",
              "      <td>7372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negatif</th>\n",
              "      <td>2916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>netral</th>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Inisialisasi TfidfVectorizer\n",
        "# max_features=5000 berarti kita hanya akan mengambil 5000 kata/fitur yang paling penting\n",
        "# Ini membantu model fokus pada kata-kata yang paling relevan dan mempercepat training\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# 2. Definisikan variabel fitur (X) dan target (y)\n",
        "# Fitur (X) adalah teks ulasan yang sudah bersih\n",
        "# Target (y) adalah label sentimen yang sudah kita buat\n",
        "X_text = df_bersih['clean_content']\n",
        "y = df_bersih['sentimen']\n",
        "\n",
        "# 3. Lakukan proses fit_transform\n",
        "# 'fit' mempelajari kosakata dari data teks Anda\n",
        "# 'transform' mengubah teks tersebut menjadi matriks angka TF-IDF\n",
        "print(\"Memulai proses ekstraksi fitur dengan TF-IDF...\")\n",
        "X = vectorizer.fit_transform(X_text)\n",
        "print(\"Ekstraksi fitur selesai.\")\n",
        "\n",
        "# 4. Periksa hasil dari proses ini\n",
        "print(f\"\\nDimensi dari matriks fitur (X): {X.shape}\")\n",
        "print(f\"Dimensi dari target (y): {y.shape}\")"
      ],
      "metadata": {
        "id": "1Sr8QodHY2rv",
        "outputId": "aa18b6be-5349-40a5-a578-5ca0992520b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai proses ekstraksi fitur dengan TF-IDF...\n",
            "Ekstraksi fitur selesai.\n",
            "\n",
            "Dimensi dari matriks fitur (X): (10692, 5000)\n",
            "Dimensi dari target (y): (10692,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 Skema 1: SVM + TF-IDF (Data 80/20)\n",
        "\n",
        "*   Item daftar\n",
        "*   Item daftar\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vHbiJlS1ZX4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pembagian Data (80% Latih, 20% Uji)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 2. Pelatihan Model SVM\n",
        "print(\"Memulai pelatihan model SVM...\")\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "print(\"Pelatihan SVM selesai.\")\n",
        "\n",
        "# 3. Evaluasi Model\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 1: SVM + TF-IDF (80/20) ---\")\n",
        "print(f\"Akurasi: {accuracy_svm * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "gxN_zHWNZbGV",
        "outputId": "8df01002-22fb-4c3d-d65c-5555af7034f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model SVM...\n",
            "Pelatihan SVM selesai.\n",
            "\n",
            "--- Hasil Skema 1: SVM + TF-IDF (80/20) ---\n",
            "Akurasi: 88.17%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.79      0.82      0.80       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.92      0.95      0.94      1475\n",
            "\n",
            "    accuracy                           0.88      2139\n",
            "   macro avg       0.57      0.59      0.58      2139\n",
            "weighted avg       0.85      0.88      0.86      2139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning"
      ],
      "metadata": {
        "id": "hM3lyXUae0LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_expanded = [\n",
        "    {\n",
        "        'kernel': ['linear'],\n",
        "        'C': [1, 10, 100]\n",
        "    },\n",
        "    {\n",
        "        'kernel': ['rbf'],\n",
        "        'C': [1, 10, 100],\n",
        "        'gamma': [0.1, 0.01, 0.001]\n",
        "    }\n",
        "]\n",
        "\n",
        "# 2. Inisialisasi GridSearchCV dengan param_grid yang baru\n",
        "# Perhatikan kita tidak lagi mendefinisikan kernel di dalam SVC()\n",
        "grid_search_expanded = GridSearchCV(\n",
        "    SVC(random_state=42), # Model dasar tanpa kernel spesifik\n",
        "    param_grid_expanded,  # Gunakan grid parameter yang sudah diperluas\n",
        "    cv=3,                 # cv=3 untuk mempercepat pencarian yang lebih kompleks ini\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# 3. Jalankan pencarian pada data latih Anda (X_train dan y_train)\n",
        "print(\"Memulai pencarian hyperparameter yang diperluas (kernel, C, gamma)...\")\n",
        "grid_search_expanded.fit(X_train, y_train)\n",
        "print(\"Pencarian selesai.\")\n",
        "\n",
        "# 4. Lihat kombinasi parameter terbaik yang ditemukan\n",
        "print(f\"\\nParameter terbaik yang ditemukan: {grid_search_expanded.best_params_}\")\n",
        "print(f\"Skor cross-validation terbaik: {grid_search_expanded.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "# 5. Gunakan model terbaik untuk membuat prediksi\n",
        "best_model_overall = grid_search_expanded.best_estimator_\n",
        "y_pred_best = best_model_overall.predict(X_test)\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "\n",
        "# 6. Tampilkan hasil akurasi yang sudah ditingkatkan\n",
        "print(f\"\\n--- Hasil Terbaik Setelah Pencarian Diperluas ---\")\n",
        "print(f\"Akurasi: {accuracy_best * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred_best))"
      ],
      "metadata": {
        "id": "zAteZzKoqsFn",
        "outputId": "a03e9a67-639b-4016-d03b-af1b07ee946f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pencarian hyperparameter yang diperluas (kernel, C, gamma)...\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Pencarian selesai.\n",
            "\n",
            "Parameter terbaik yang ditemukan: {'C': 1, 'kernel': 'linear'}\n",
            "Skor cross-validation terbaik: 0.8741\n",
            "\n",
            "--- Hasil Terbaik Setelah Pencarian Diperluas ---\n",
            "Akurasi: 88.17%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.79      0.82      0.80       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.92      0.95      0.94      1475\n",
            "\n",
            "    accuracy                           0.88      2139\n",
            "   macro avg       0.57      0.59      0.58      2139\n",
            "weighted avg       0.85      0.88      0.86      2139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🌳 Skema 2: Random Forest + Word2Vec (Data 80/20)\n"
      ],
      "metadata": {
        "id": "AiBEAcneaveG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# A. Tokenisasi data teks (Word2Vec butuh input berupa list of list of words)\n",
        "tokenized_text = [text.split() for text in df_bersih['clean_content']]\n",
        "\n",
        "# B. Latih model Word2Vec\n",
        "# size: dimensi vektor, window: jarak kata, min_count: abaikan kata yg jarang muncul\n",
        "print(\"Memulai pelatihan model Word2Vec...\")\n",
        "w2v_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
        "print(\"Pelatihan Word2Vec selesai.\")\n",
        "\n",
        "# C. Ubah setiap ulasan menjadi satu vektor rata-rata\n",
        "def vectorize_review(review, model):\n",
        "    words = review.split()\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv.key_to_index]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "X_w2v = np.array([vectorize_review(review, w2v_model) for review in df_bersih['clean_content']])\n",
        "y_w2v = df_bersih['sentimen']\n",
        "\n",
        "print(f\"Dimensi matriks fitur Word2Vec (X_w2v): {X_w2v.shape}\")"
      ],
      "metadata": {
        "id": "qgaeWZlmZ_9P",
        "outputId": "fabfbe06-6561-46ae-b149-bef63620b25d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model Word2Vec...\n",
            "Pelatihan Word2Vec selesai.\n",
            "Dimensi matriks fitur Word2Vec (X_w2v): (10692, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Pembagian Data (80% Latih, 20% Uji)\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(\n",
        "    X_w2v, y_w2v,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_w2v\n",
        ")\n",
        "\n",
        "# 2. Pelatihan Model Random Forest\n",
        "print(\"Memulai pelatihan model Random Forest...\")\n",
        "rf_model_w2v = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model_w2v.fit(X_train_w2v, y_train_w2v)\n",
        "print(\"Pelatihan Random Forest selesai.\")\n",
        "\n",
        "# 3. Evaluasi Model\n",
        "y_pred_rf_w2v = rf_model_w2v.predict(X_test_w2v)\n",
        "accuracy_rf_w2v = accuracy_score(y_test_w2v, y_pred_rf_w2v)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 2: RF + Word2Vec (80/20) ---\")\n",
        "print(f\"Akurasi: {accuracy_rf_w2v * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_w2v, y_pred_rf_w2v))"
      ],
      "metadata": {
        "id": "AzRRZeOOadpw",
        "outputId": "83739122-dc0e-4aa0-90ea-a3430298d398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model Random Forest...\n",
            "Pelatihan Random Forest selesai.\n",
            "\n",
            "--- Hasil Skema 2: RF + Word2Vec (80/20) ---\n",
            "Akurasi: 83.82%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.71      0.74      0.73       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.89      0.92      0.90      1475\n",
            "\n",
            "    accuracy                           0.84      2139\n",
            "   macro avg       0.53      0.55      0.54      2139\n",
            "weighted avg       0.81      0.84      0.82      2139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TUNING KE 85"
      ],
      "metadata": {
        "id": "sa62X76XAPam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definisikan parameter yang ingin diuji\n",
        "# Kita akan menguji beberapa pengaturan umum DAN parameter class_weight\n",
        "param_grid_rf_w2v = {\n",
        "    'n_estimators': [100, 200],              # Jumlah pohon\n",
        "    'max_depth': [10, 20, None],             # Kedalaman maksimum pohon\n",
        "    'min_samples_leaf': [1, 2],              # Jumlah minimum sampel di daun\n",
        "    'class_weight': [None, 'balanced']       # <-- PENTING: Uji dengan dan tanpa bobot kelas\n",
        "}\n",
        "\n",
        "# 2. Inisialisasi GridSearchCV\n",
        "grid_search_rf_w2v = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    param_grid_rf_w2v,\n",
        "    cv=3,  # cv=3 untuk mempercepat proses pencarian\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# 3. Jalankan pencarian pada data latih Anda\n",
        "print(\"Memulai pencarian hyperparameter terbaik untuk Random Forest + Word2Vec...\")\n",
        "grid_search_rf_w2v.fit(X_train_w2v, y_train_w2v)\n",
        "print(\"Pencarian selesai.\")\n",
        "\n",
        "# 4. Lihat parameter terbaik yang ditemukan\n",
        "print(f\"\\nParameter terbaik yang ditemukan: {grid_search_rf_w2v.best_params_}\")\n",
        "\n",
        "# 5. Gunakan model terbaik untuk membuat prediksi\n",
        "best_rf_model_w2v = grid_search_rf_w2v.best_estimator_\n",
        "y_pred_best_rf_w2v = best_rf_model_w2v.predict(X_test_w2v)\n",
        "accuracy_best_rf_w2v = accuracy_score(y_test_w2v, y_pred_best_rf_w2v)\n",
        "\n",
        "# 6. Tampilkan hasil akurasi yang sudah ditingkatkan\n",
        "print(f\"\\n--- Hasil Skema 2 (Setelah Tuning) ---\")\n",
        "print(f\"Akurasi: {accuracy_best_rf_w2v * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_w2v, y_pred_best_rf_w2v))"
      ],
      "metadata": {
        "id": "adMabdNyAVlx",
        "outputId": "9f1237da-22fe-4818-e608-a68a5eef4851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pencarian hyperparameter terbaik untuk Random Forest + Word2Vec...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Pencarian selesai.\n",
            "\n",
            "Parameter terbaik yang ditemukan: {'class_weight': None, 'max_depth': None, 'min_samples_leaf': 2, 'n_estimators': 200}\n",
            "\n",
            "--- Hasil Skema 2 (Setelah Tuning) ---\n",
            "Akurasi: 83.78%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.71      0.74      0.73       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.89      0.92      0.90      1475\n",
            "\n",
            "    accuracy                           0.84      2139\n",
            "   macro avg       0.53      0.56      0.54      2139\n",
            "weighted avg       0.81      0.84      0.82      2139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Tahap 1: Buat Bobot TF-IDF untuk Setiap Kata\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Melatih TfidfVectorizer untuk mendapatkan bobot kata...\")\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "# Kita hanya perlu 'fit' untuk mempelajari kosakatanya\n",
        "tfidf_vectorizer.fit(df_bersih['clean_content'])\n",
        "# Buat dictionary yang memetakan setiap kata ke bobot IDF-nya\n",
        "word_idf_weights = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Tahap 2: Buat Fungsi Vektorisasi Baru yang Menggunakan Bobot TF-IDF\n",
        "# ==============================================================================\n",
        "\n",
        "def vectorize_review_weighted(review, w2v_model, idf_weights):\n",
        "    words = review.split()\n",
        "    word_vectors = []\n",
        "\n",
        "    for word in words:\n",
        "        # Cek apakah kata ada di model Word2Vec DAN di kamus IDF\n",
        "        if word in w2v_model.wv and word in idf_weights:\n",
        "            # Kalikan vektor kata dengan bobot IDF-nya\n",
        "            # Ini memberikan \"kepentingan\" lebih pada kata-kata yang lebih unik\n",
        "            word_vectors.append(w2v_model.wv[word] * idf_weights[word])\n",
        "\n",
        "    if not word_vectors:\n",
        "        # Jika tidak ada kata yang valid, kembalikan vektor nol\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "\n",
        "    # Rata-ratakan vektor yang sudah diboboti\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Tahap 3: Buat Fitur Baru, Latih, dan Evaluasi Model\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nMembuat fitur TF-IDF Weighted Word2Vec...\")\n",
        "# Terapkan fungsi baru untuk membuat matriks fitur yang lebih baik\n",
        "X_w2v_weighted = np.array([vectorize_review_weighted(r, w2v_model, word_idf_weights) for r in df_bersih['clean_content']])\n",
        "y_w2v_weighted = df_bersih['sentimen']\n",
        "\n",
        "# Pembagian Data\n",
        "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
        "    X_w2v_weighted, y_w2v_weighted, test_size=0.2, random_state=42, stratify=y_w2v_weighted\n",
        ")\n",
        "\n",
        "# Inisialisasi dan Latih Model Random Forest\n",
        "rf_model_w2v_weighted = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"\\nMemulai pelatihan Random Forest dengan fitur baru yang telah ditingkatkan...\")\n",
        "rf_model_w2v_weighted.fit(X_train_w, y_train_w)\n",
        "print(\"Pelatihan selesai.\")\n",
        "\n",
        "# Evaluasi Model\n",
        "y_pred_w = rf_model_w2v_weighted.predict(X_test_w)\n",
        "accuracy_w = accuracy_score(y_test_w, y_pred_w)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 2 (dengan TF-IDF Weighted Word2Vec) ---\")\n",
        "print(f\"Akurasi: {accuracy_w * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_w, y_pred_w))"
      ],
      "metadata": {
        "id": "u8pj1jf7L7BC",
        "outputId": "28f43e1c-2d17-4bfd-8138-ebdf2c0e9694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih TfidfVectorizer untuk mendapatkan bobot kata...\n",
            "\n",
            "Membuat fitur TF-IDF Weighted Word2Vec...\n",
            "\n",
            "Memulai pelatihan Random Forest dengan fitur baru yang telah ditingkatkan...\n",
            "Pelatihan selesai.\n",
            "\n",
            "--- Hasil Skema 2 (dengan TF-IDF Weighted Word2Vec) ---\n",
            "Akurasi: 84.43%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.73      0.74      0.74       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.89      0.93      0.91      1475\n",
            "\n",
            "    accuracy                           0.84      2139\n",
            "   macro avg       0.54      0.56      0.55      2139\n",
            "weighted avg       0.81      0.84      0.83      2139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Tahap 1: Latih Ulang Model Word2Vec dengan Parameter yang Ditingkatkan\n",
        "# ==============================================================================\n",
        "print(\"Memulai pelatihan model Word2Vec yang ditingkatkan...\")\n",
        "w2v_model_tuned = Word2Vec(\n",
        "    sentences=tokenized_text,\n",
        "    vector_size=200,  # <-- Ditingkatkan dari 100 menjadi 200\n",
        "    window=10,        # <-- Ditingkatkan dari 5 menjadi 10\n",
        "    min_count=2,      # <-- Abaikan kata yang hanya muncul 1x (mengurangi noise)\n",
        "    sg=1,             # <-- Gunakan algoritma Skip-gram\n",
        "    workers=4\n",
        ")\n",
        "print(\"Pelatihan Word2Vec selesai.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Tahap 2: Buat Ulang Fitur Dokumen dan Latih Model RF\n",
        "# ==============================================================================\n",
        "\n",
        "# Fungsi untuk membuat vektor rata-rata (tetap sama)\n",
        "def vectorize_review(review, model):\n",
        "    words = review.split()\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "# Buat fitur baru dengan model Word2Vec yang sudah di-tuning\n",
        "print(\"\\nMembuat fitur dokumen baru dengan Word2Vec yang ditingkatkan...\")\n",
        "X_w2v_tuned = np.array([vectorize_review(review, w2v_model_tuned) for review in df_bersih['clean_content']])\n",
        "y_w2v_tuned = df_bersih['sentimen']\n",
        "\n",
        "# Pembagian Data\n",
        "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
        "    X_w2v_tuned, y_w2v_tuned, test_size=0.2, random_state=42, stratify=y_w2v_tuned\n",
        ")\n",
        "\n",
        "# Latih model RF (kita bisa langsung gunakan class_weight='balanced' karena itu memberi sedikit kenaikan)\n",
        "rf_model_tuned_w2v = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nMemulai pelatihan Random Forest dengan fitur baru...\")\n",
        "rf_model_tuned_w2v.fit(X_train_t, y_train_t)\n",
        "print(\"Pelatihan selesai.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Tahap 3: Evaluasi Hasil Akhir\n",
        "# ==============================================================================\n",
        "y_pred_tuned = rf_model_tuned_w2v.predict(X_test_t)\n",
        "accuracy_tuned = accuracy_score(y_test_t, y_pred_tuned)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 2 (Setelah Tuning Word2Vec) ---\")\n",
        "print(f\"Akurasi: {accuracy_tuned * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_t, y_pred_tuned))"
      ],
      "metadata": {
        "id": "Qtsf34-StG3h",
        "outputId": "1c28874c-e39c-4305-c3e2-dab53582e36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model Word2Vec yang ditingkatkan...\n",
            "Pelatihan Word2Vec selesai.\n",
            "\n",
            "Membuat fitur dokumen baru dengan Word2Vec yang ditingkatkan...\n",
            "\n",
            "Memulai pelatihan Random Forest dengan fitur baru...\n",
            "Pelatihan selesai.\n",
            "\n",
            "--- Hasil Skema 2 (Setelah Tuning Word2Vec) ---\n",
            "Akurasi: 85.55%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.73      0.81      0.77       583\n",
            "      netral       0.00      0.00      0.00        81\n",
            "     positif       0.91      0.92      0.92      1475\n",
            "\n",
            "    accuracy                           0.86      2139\n",
            "   macro avg       0.55      0.58      0.56      2139\n",
            "weighted avg       0.83      0.86      0.84      2139\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🌲 Skema 3: Random Forest + TF-IDF (Data 70/30)\n"
      ],
      "metadata": {
        "id": "npTclCYK5E61"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgDlhj8iAVLx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pembagian Data (70% Latih, 30% Uji)\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3, # Perhatikan test_size diubah menjadi 0.3\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 2. Pelatihan Model Random Forest\n",
        "print(\"Memulai pelatihan model Random Forest...\")\n",
        "rf_model_tfidf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model_tfidf.fit(X_train_rf, y_train_rf)\n",
        "print(\"Pelatihan Random Forest selesai.\")\n",
        "\n",
        "# 3. Evaluasi Model\n",
        "y_pred_rf_tfidf = rf_model_tfidf.predict(X_test_rf)\n",
        "accuracy_rf_tfidf = accuracy_score(y_test_rf, y_pred_rf_tfidf)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 3: RF + TF-IDF (70/30) ---\")\n",
        "print(f\"Akurasi: {accuracy_rf_tfidf * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_rf, y_pred_rf_tfidf))"
      ],
      "metadata": {
        "id": "VUjJA00rarDh",
        "outputId": "60defd92-e71a-4f71-f1a1-fe873cd33d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model Random Forest...\n",
            "Pelatihan Random Forest selesai.\n",
            "\n",
            "--- Hasil Skema 3: RF + TF-IDF (70/30) ---\n",
            "Akurasi: 87.03%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.74      0.85      0.79       875\n",
            "      netral       0.00      0.00      0.00       121\n",
            "     positif       0.93      0.93      0.93      2212\n",
            "\n",
            "    accuracy                           0.87      3208\n",
            "   macro avg       0.56      0.59      0.57      3208\n",
            "weighted avg       0.84      0.87      0.86      3208\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model dengan parameter terbaik DAN class_weight\n",
        "rf_model_balanced = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    class_weight='balanced', # <-- Tambahkan parameter penting ini\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Memulai pelatihan Random Forest dengan class_weight='balanced'...\")\n",
        "rf_model_balanced.fit(X_train_rf, y_train_rf)\n",
        "print(\"Pelatihan selesai.\")\n",
        "\n",
        "# Evaluasi Model\n",
        "y_pred_balanced_rf = rf_model_balanced.predict(X_test_rf)\n",
        "accuracy_balanced_rf = accuracy_score(y_test_rf, y_pred_balanced_rf)\n",
        "\n",
        "print(f\"\\n--- Hasil Skema 3 (dengan Class Weight Balanced) ---\")\n",
        "print(f\"Akurasi: {accuracy_balanced_rf * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_rf, y_pred_balanced_rf))"
      ],
      "metadata": {
        "id": "5f7103oO6rAo",
        "outputId": "86f4f28e-c7c4-43c3-f540-6cf2f5b852c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan Random Forest dengan class_weight='balanced'...\n",
            "Pelatihan selesai.\n",
            "\n",
            "--- Hasil Skema 3 (dengan Class Weight Balanced) ---\n",
            "Akurasi: 86.91%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.75      0.84      0.79       875\n",
            "      netral       0.00      0.00      0.00       121\n",
            "     positif       0.93      0.93      0.93      2212\n",
            "\n",
            "    accuracy                           0.87      3208\n",
            "   macro avg       0.56      0.59      0.57      3208\n",
            "weighted avg       0.84      0.87      0.86      3208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definisikan parameter yang ingin diuji\n",
        "# Ini adalah beberapa pengaturan umum yang bagus untuk memulai\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],      # Coba dengan 100 atau 200 pohon\n",
        "    'max_depth': [None, 10, 20],     # Coba tanpa batas kedalaman, atau kedalaman 10 dan 20\n",
        "    'min_samples_leaf': [1, 2],      # Coba dengan minimal 1 atau 2 sampel di daun\n",
        "}\n",
        "\n",
        "# 2. Inisialisasi GridSearchCV\n",
        "grid_search_rf = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid_rf,\n",
        "    cv=3,  # cv=3 untuk mempercepat proses pencarian\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# 3. Jalankan pencarian pada data latih Anda\n",
        "print(\"Memulai pencarian hyperparameter terbaik untuk Random Forest...\")\n",
        "grid_search_rf.fit(X_train_rf, y_train_rf)\n",
        "print(\"Pencarian selesai.\")\n",
        "\n",
        "# 4. Lihat parameter terbaik yang ditemukan\n",
        "print(f\"\\nParameter terbaik yang ditemukan: {grid_search_rf.best_params_}\")\n",
        "\n",
        "# 5. Gunakan model terbaik untuk membuat prediksi\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test_rf)\n",
        "accuracy_best_rf = accuracy_score(y_test_rf, y_pred_best_rf)\n",
        "\n",
        "# 6. Tampilkan hasil akurasi yang sudah ditingkatkan\n",
        "print(f\"\\n--- Hasil Skema 3 (Setelah Tuning) ---\")\n",
        "print(f\"Akurasi: {accuracy_best_rf * 100:.2f}%\")\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_rf, y_pred_best_rf))"
      ],
      "metadata": {
        "id": "PjriP4Vj5cu5",
        "outputId": "2934b4d0-ec75-4267-e51c-61aebdd62979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pencarian hyperparameter terbaik untuk Random Forest...\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Pencarian selesai.\n",
            "\n",
            "Parameter terbaik yang ditemukan: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
            "\n",
            "--- Hasil Skema 3 (Setelah Tuning) ---\n",
            "Akurasi: 87.03%\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.74      0.84      0.79       875\n",
            "      netral       0.00      0.00      0.00       121\n",
            "     positif       0.93      0.93      0.93      2212\n",
            "\n",
            "    accuracy                           0.87      3208\n",
            "   macro avg       0.56      0.59      0.57      3208\n",
            "weighted avg       0.84      0.87      0.86      3208\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 Skema 1: SVM + TF-IDF (Data 80/20)\n",
        "Terbagus 88.17"
      ],
      "metadata": {
        "id": "v0gSB7Ylzoev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_cepat(text):\n",
        "    # 1. Case Folding: Mengubah teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Punctuation & Number Removal: Menghapus karakter, angka, dan spasi berlebih\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # 3. Tokenization: Memecah kalimat menjadi token (kata)\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 4. Stopword Removal: Menghapus kata-kata umum\n",
        "    stop_words = set(stopwords.words('indonesian'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Menggabungkan kembali token menjadi kalimat\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "print(\"Fungsi 'preprocess_text_cepat' berhasil didefinisikan dan siap digunakan.\")"
      ],
      "metadata": {
        "id": "ir7wvIyX03cJ",
        "outputId": "77d6ebca-9aef-4029-9c45-1996e6f3207b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi 'preprocess_text_cepat' berhasil didefinisikan dan siap digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "\n",
        "# --- Langkah 1: Siapkan Data Uji Baru ---\n",
        "# Ini adalah contoh ulasan baru yang belum pernah dilihat model\n",
        "ulasan_baru = [\n",
        "    \"Aplikasinya keren dan sangat membantu, drivernya juga ramah banget!\",\n",
        "    \"Sering error dan tidak bisa login, sangat mengecewakan pelayanannya.\",\n",
        "    \"Biasa saja sih, fiturnya standar tidak ada yang spesial.\",\n",
        "    \"kenapa sekarang jadi lambat sekali loadingnya?\",\n",
        "    \"terima kasih gojek, promonya mantap\"\n",
        "]\n",
        "\n",
        "print(\"Data ulasan baru yang akan dites:\")\n",
        "for ulasan in ulasan_baru:\n",
        "    print(f\"- {ulasan}\")\n",
        "\n",
        "\n",
        "# --- Langkah 2: Lakukan Preprocessing pada Data Baru ---\n",
        "# Gunakan fungsi preprocessing yang SAMA PERSIS dengan saat training\n",
        "print(\"\\nMelakukan preprocessing pada data baru...\")\n",
        "ulasan_baru_bersih = [preprocess_text_cepat(ulasan) for ulasan in ulasan_baru]\n",
        "\n",
        "\n",
        "# --- Langkah 3: Lakukan Ekstraksi Fitur (Transformasi) ---\n",
        "# PENTING: Gunakan objek 'vectorizer' yang sudah di-fit sebelumnya.\n",
        "# Gunakan .transform(), JANGAN .fit_transform() lagi.\n",
        "print(\"Melakukan ekstraksi fitur (transformasi) pada data baru...\")\n",
        "fitur_ulasan_baru = vectorizer.transform(ulasan_baru_bersih)\n",
        "\n",
        "\n",
        "# --- Langkah 4: Lakukan Prediksi dengan Model Terbaik Anda ---\n",
        "print(\"Melakukan prediksi sentimen...\")\n",
        "prediksi_sentimen = svm_model.predict(fitur_ulasan_baru)\n",
        "\n",
        "\n",
        "# --- Langkah 5: Tampilkan Hasil Prediksi ---\n",
        "print(\"\\n--- Hasil Prediksi Sentimen ---\")\n",
        "for i in range(len(ulasan_baru)):\n",
        "    print(f\"Ulasan: \\\"{ulasan_baru[i]}\\\"\")\n",
        "    print(f\"Prediksi Sentimen: {prediksi_sentimen[i].upper()}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "h-vjAc930MFX",
        "outputId": "4bb4c9df-b718-4311-fe19-b81d6e0f6aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ulasan baru yang akan dites:\n",
            "- Aplikasinya keren dan sangat membantu, drivernya juga ramah banget!\n",
            "- Sering error dan tidak bisa login, sangat mengecewakan pelayanannya.\n",
            "- Biasa saja sih, fiturnya standar tidak ada yang spesial.\n",
            "- kenapa sekarang jadi lambat sekali loadingnya?\n",
            "- terima kasih gojek, promonya mantap\n",
            "\n",
            "Melakukan preprocessing pada data baru...\n",
            "Melakukan ekstraksi fitur (transformasi) pada data baru...\n",
            "Melakukan prediksi sentimen...\n",
            "\n",
            "--- Hasil Prediksi Sentimen ---\n",
            "Ulasan: \"Aplikasinya keren dan sangat membantu, drivernya juga ramah banget!\"\n",
            "Prediksi Sentimen: POSITIF\n",
            "------------------------------\n",
            "Ulasan: \"Sering error dan tidak bisa login, sangat mengecewakan pelayanannya.\"\n",
            "Prediksi Sentimen: NEGATIF\n",
            "------------------------------\n",
            "Ulasan: \"Biasa saja sih, fiturnya standar tidak ada yang spesial.\"\n",
            "Prediksi Sentimen: POSITIF\n",
            "------------------------------\n",
            "Ulasan: \"kenapa sekarang jadi lambat sekali loadingnya?\"\n",
            "Prediksi Sentimen: NEGATIF\n",
            "------------------------------\n",
            "Ulasan: \"terima kasih gojek, promonya mantap\"\n",
            "Prediksi Sentimen: POSITIF\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}